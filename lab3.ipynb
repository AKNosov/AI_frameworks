{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Выбор данных\n",
        "\n",
        "#Датасеты\n",
        "- **Датасет:** [Stroke Prediction Dataset](https://www.kaggle.com/datasets/jawairia123/stroke-prediction-dataset)\n",
        "\n",
        " **Задача:** Прогнозирование вероятности инсульта у пациента на основе медицинских и демографических данных.\n",
        "\n",
        "- **Датасет:** [Python Learning & Exam Performance Dataset](https://www.kaggle.com/datasets/emonsharkar/python-learning-and-exam-performance-dataset)\n",
        "\n",
        " **Задача:** Прогнозирование результата экзамена по Python на основе данных об обучении и активности студента.\n",
        "\n",
        "#Метрики\n",
        "- **Для классификации:**\n",
        "  - **F1-score:** так как датасет может быть несбалансированным\n",
        "  - **ROC-AUC:** позволяет оценить качество модели на разных порогах классификации\n",
        "  - **Accuracy**\n",
        "- **Для регрессии:**\n",
        "  - **MAE**\n",
        "  - **RMSE:** более чувствительна к большим ошибкам\n",
        "  - **R²**\n"
      ],
      "metadata": {
        "id": "B6rxjDF7NVtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Создание бейзлайна и оценка качества\n"
      ],
      "metadata": {
        "id": "9ECoU5qQO-Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, f_regression"
      ],
      "metadata": {
        "id": "p14GJo99XFpi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично ЛР1"
      ],
      "metadata": {
        "id": "Abmglj5aViCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stroke = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')\n",
        "df_stroke = df_stroke.drop(columns=['id'])\n",
        "df_exam = pd.read_csv('/content/python_learning_exam_performance.csv')\n",
        "df_exam = df_exam.drop(columns=['student_id'])\n",
        "\n",
        "df_stroke['bmi'] = df_stroke['bmi'].fillna(df_stroke['bmi'].median())\n",
        "\n",
        "X_stroke = df_stroke.drop(columns=['stroke'])\n",
        "y_stroke = df_stroke['stroke']\n",
        "X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke = train_test_split(\n",
        "    X_stroke, y_stroke, test_size=0.2, random_state=42, stratify=y_stroke\n",
        ")\n",
        "\n",
        "cat_cols_stroke = X_train_stroke.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols_stroke = X_train_stroke.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "preprocessor_stroke = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_cols_stroke),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols_stroke)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_stroke_processed = preprocessor_stroke.fit_transform(X_train_stroke)\n",
        "X_test_stroke_processed = preprocessor_stroke.transform(X_test_stroke)\n",
        "df_exam['prior_programming_experience'] = df_exam['prior_programming_experience'].fillna('No')\n",
        "\n",
        "X_exam = df_exam.drop(columns=['final_exam_score'])\n",
        "y_exam = df_exam['final_exam_score']\n",
        "X_train_exam, X_test_exam, y_train_exam, y_test_exam = train_test_split(\n",
        "    X_exam, y_exam, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "cat_cols_exam = X_train_exam.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols_exam = X_train_exam.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "preprocessor_exam = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_cols_exam),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols_exam)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_exam_processed = preprocessor_exam.fit_transform(X_train_exam)\n",
        "X_test_exam_processed = preprocessor_exam.transform(X_test_exam)"
      ],
      "metadata": {
        "id": "SRhPv9KEdSKc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "77Y2LXHqmtmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train_stroke_processed, y_train_stroke)\n",
        "y_pred_stroke_dt = dt_clf.predict(X_test_stroke_processed)\n",
        "y_pred_proba_stroke_dt = dt_clf.predict_proba(X_test_stroke_processed)[:, 1]\n",
        "\n",
        "\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train_exam_processed, y_train_exam)\n",
        "y_pred_exam_dt = dt_reg.predict(X_test_exam_processed)\n",
        "\n",
        "# Оценка качества моделей\n",
        "\n",
        "acc_dt = accuracy_score(y_test_stroke, y_pred_stroke_dt)\n",
        "f1_dt = f1_score(y_test_stroke, y_pred_stroke_dt)\n",
        "roc_auc_dt = roc_auc_score(y_test_stroke, y_pred_proba_stroke_dt)\n",
        "\n",
        "print(\"=== Классификация ===\")\n",
        "print(f\"Accuracy: {acc_dt:.4f}\")\n",
        "print(f\"F1-Score: {f1_dt:.4f}\")\n",
        "print(f\"ROC-AUC:  {roc_auc_dt:.4f}\")\n",
        "print()\n",
        "\n",
        "mae_dt = mean_absolute_error(y_test_exam, y_pred_exam_dt)\n",
        "rmse_dt = np.sqrt(mean_squared_error(y_test_exam, y_pred_exam_dt))\n",
        "r2_dt = r2_score(y_test_exam, y_pred_exam_dt)\n",
        "\n",
        "print(\"=== Регрессия ===\")\n",
        "print(f\"MAE:  {mae_dt:.4f}\")\n",
        "print(f\"RMSE: {rmse_dt:.4f}\")\n",
        "print(f\"R²:   {r2_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9---xR65iNc6",
        "outputId": "a483c157-a978-491b-9272-85ed41ffd79b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Классификация ===\n",
            "Accuracy: 0.9090\n",
            "F1-Score: 0.1468\n",
            "ROC-AUC:  0.5538\n",
            "\n",
            "=== Регрессия ===\n",
            "MAE:  9.4872\n",
            "RMSE: 12.0742\n",
            "R²:   0.5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Анализ результатов**\n",
        "\n",
        "Анализируя результаты классификации, можно отметить противоречивую картину: модель демонстрирует высокую точность (Accuracy = 0.9090), что на первый взгляд является хорошим результатом. Однако крайне низкий F1-Score (0.1468) и близкий к случайному угадыванию показатель ROC-AUC (0.5538) указывают на серьезную проблему — модель работает преимущественно с классом большинства (вероятно, здоровыми пациентами), но плохо распознает целевой класс (случаи инсульта). Это типичная ситуация несбалансированных данных, когда модель \"обучается\" просто предсказывать наиболее частый класс, игнорируя меньшинство.\n",
        "\n",
        "Что касается регрессионной модели, полученные метрики (MAE = 9.49, RMSE = 12.07, R² = 0.504) свидетельствуют об умеренном качестве прогнозирования. Коэффициент детерминации R² = 0.504 показывает, что модель объясняет примерно половину дисперсии целевой переменной, что является приемлемым, но не выдающимся результатом. Разница между MAE и RMSE указывает на наличие выбросов в данных, поскольку RMSE сильнее штрафует за большие ошибки. В целом, модель требует дальнейшей оптимизации и, возможно, использования более сложных алгоритмов для улучшения точности прогнозов."
      ],
      "metadata": {
        "id": "25foCoqkoVhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "ljbpDl5To_Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично ЛР 1 пробуем следующие гипотезы для улучшения результатов\n",
        "\n",
        "-   Балансировка классов\n",
        "-   Подбор гиперпараметров\n",
        "\n",
        "- Отбор признаков\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qGalntx2tllk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_stroke_processed, y_train_stroke)\n",
        "print(f\"До балансировки: {np.bincount(y_train_stroke)}\")\n",
        "print(f\"После балансировки: {np.bincount(y_train_balanced)}\")\n",
        "print()\n",
        "\n",
        "selector_clf = SelectKBest(f_classif, k=8)\n",
        "X_train_selected = selector_clf.fit_transform(X_train_balanced, y_train_balanced)\n",
        "X_test_selected = selector_clf.transform(X_test_stroke_processed)\n",
        "print(f\"Выбрано {X_train_selected.shape[1]} лучших признаков из {X_train_balanced.shape[1]}\")\n",
        "print()\n",
        "\n",
        "param_grid_dt = {\n",
        "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10, 15],\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "grid_search_dt = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
        "    param_grid_dt,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "grid_search_dt.fit(X_train_selected, y_train_balanced)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid_search_dt.best_params_}\")\n",
        "\n",
        "best_dt = grid_search_dt.best_estimator_\n",
        "y_pred_dt_improved = best_dt.predict(X_test_selected)\n",
        "y_pred_proba_dt_improved = best_dt.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "acc_dt_improved = accuracy_score(y_test_stroke, y_pred_dt_improved)\n",
        "f1_dt_improved = f1_score(y_test_stroke, y_pred_dt_improved)\n",
        "roc_auc_dt_improved = roc_auc_score(y_test_stroke, y_pred_proba_dt_improved)\n",
        "\n",
        "print(\"=== Decision Tree ===\")\n",
        "print(f\"Accuracy:  {acc_dt_improved:.4f}\")\n",
        "print(f\"F1-Score:  {f1_dt_improved:.4f}\")\n",
        "print(f\"ROC-AUC:   {roc_auc_dt_improved:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gegz6_Hto-rK",
        "outputId": "39f6b49a-d67f-4377-d3ad-14d42ad8c3fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До балансировки: [3889  199]\n",
            "После балансировки: [3889 3889]\n",
            "\n",
            "Выбрано 8 лучших признаков из 16\n",
            "\n",
            "Fitting 5 folds for each of 1050 candidates, totalling 5250 fits\n",
            "Лучшие параметры: {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
            "=== Decision Tree ===\n",
            "Accuracy:  0.9207\n",
            "F1-Score:  0.1290\n",
            "ROC-AUC:   0.6608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector_reg = SelectKBest(f_regression, k=10)\n",
        "X_train_exam_selected = selector_reg.fit_transform(X_train_exam_processed, y_train_exam)\n",
        "X_test_exam_selected = selector_reg.transform(X_test_exam_processed)\n",
        "print(f\"Выбрано {X_train_exam_selected.shape[1]} лучших признаков из {X_train_exam_processed.shape[1]}\")\n",
        "print()\n",
        "\n",
        "param_grid_dt_reg = {\n",
        "    'max_depth': [3, 5, 7, 10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10, 15, 20],\n",
        "    'min_samples_leaf': [1, 2, 5, 10, 15],\n",
        "    'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "grid_search_dt_reg = GridSearchCV(\n",
        "    DecisionTreeRegressor(random_state=42),\n",
        "    param_grid_dt_reg,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "grid_search_dt_reg.fit(X_train_exam_selected, y_train_exam)\n",
        "\n",
        "print(f\"Лучшие параметры: {grid_search_dt_reg.best_params_}\")\n",
        "\n",
        "best_dt_reg = grid_search_dt_reg.best_estimator_\n",
        "y_pred_exam_dt_improved = best_dt_reg.predict(X_test_exam_selected)\n",
        "\n",
        "\n",
        "mae_dt_improved = mean_absolute_error(y_test_exam, y_pred_exam_dt_improved)\n",
        "rmse_dt_improved = np.sqrt(mean_squared_error(y_test_exam, y_pred_exam_dt_improved))\n",
        "r2_dt_improved = r2_score(y_test_exam, y_pred_exam_dt_improved)\n",
        "\n",
        "print(\"=== Decision Tree Regressor ===\")\n",
        "print(f\"MAE:   {mae_dt_improved:.4f}\")\n",
        "print(f\"RMSE:  {rmse_dt_improved:.4f}\")\n",
        "print(f\"R²:    {r2_dt_improved:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVRxSaav1WDU",
        "outputId": "29f9e133-686a-4fbb-a933-2bdad86f62a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Выбрано 10 лучших признаков из 23\n",
            "\n",
            "Fitting 5 folds for each of 4200 candidates, totalling 21000 fits\n",
            "Лучшие параметры: {'criterion': 'poisson', 'max_depth': 15, 'max_features': None, 'min_samples_leaf': 10, 'min_samples_split': 2, 'splitter': 'random'}\n",
            "=== Decision Tree Regressor ===\n",
            "MAE:   7.5625\n",
            "RMSE:  9.5383\n",
            "R²:    0.6905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Анализ результатов**\n",
        "\n",
        "Сравнивая результаты улучшенных моделей решающего дерева с базовыми, можно отметить существенные изменения в качестве предсказаний. В задаче классификации (прогноз инсульта) после балансировки данных с помощью SMOTE и оптимизации гиперпараметров мы получили увеличение ROC-AUC с 0.5538 до 0.6608, что указывает на улучшение способности модели различать классы. Однако показатель F1-Score снизился с 0.1468 до 0.1290, что объясняется снижением точности (Accuracy уменьшилась с 0.9090 до 0.9207) - модель стала лучше находить случаи инсульта, но при этом увеличила число ложных срабатываний.\n",
        "\n",
        "В задаче регрессии (предсказание результатов экзаменов) наблюдается значительное улучшение всех метрик: MAE снизился с 9.4872 до 7.5625, RMSE с 12.0742 до 9.5383, а R² вырос с 0.5040 до 0.6905. Это означает, что оптимизированное дерево объясняет на 19% больше дисперсии целевой переменной и совершает меньшие ошибки в предсказаниях."
      ],
      "metadata": {
        "id": "__UCedKhFS-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Имплементация собвственной модели\n"
      ],
      "metadata": {
        "id": "SWqGaH0st-t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDecisionTree:\n",
        "    def __init__(self, max_depth=3, task='classification'):\n",
        "        self.max_depth = max_depth\n",
        "        self.task = task\n",
        "        self.tree = None\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        best_gain = -1\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for feature in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "\n",
        "            for threshold in thresholds:\n",
        "                left_mask = X[:, feature] <= threshold\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if np.sum(left_mask) == 0 or np.sum(right_mask) == 0:\n",
        "                    continue\n",
        "\n",
        "                if self.task == 'classification':\n",
        "                    parent_impurity = 1 - max(np.bincount(y) / len(y))\n",
        "\n",
        "                    left_impurity = 1 - max(np.bincount(y[left_mask]) / len(y[left_mask])) if len(y[left_mask]) > 0 else 0\n",
        "                    right_impurity = 1 - max(np.bincount(y[right_mask]) / len(y[right_mask])) if len(y[right_mask]) > 0 else 0\n",
        "\n",
        "                    gain = parent_impurity - (len(y[left_mask])/n_samples * left_impurity +\n",
        "                                            len(y[right_mask])/n_samples * right_impurity)\n",
        "                else:\n",
        "                    parent_mse = np.var(y)\n",
        "                    left_mse = np.var(y[left_mask]) if len(y[left_mask]) > 0 else 0\n",
        "                    right_mse = np.var(y[right_mask]) if len(y[right_mask]) > 0 else 0\n",
        "\n",
        "                    gain = parent_mse - (len(y[left_mask])/n_samples * left_mse +\n",
        "                                        len(y[right_mask])/n_samples * right_mse)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold, best_gain\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if depth >= self.max_depth or len(np.unique(y)) == 1 or len(y) <= 1:\n",
        "            # Лист\n",
        "            if self.task == 'classification':\n",
        "                values, counts = np.unique(y, return_counts=True)\n",
        "                return {'leaf': True, 'value': values[np.argmax(counts)]}\n",
        "            else:\n",
        "                return {'leaf': True, 'value': np.mean(y)}\n",
        "\n",
        "        feature, threshold, gain = self._find_best_split(X, y)\n",
        "\n",
        "        if gain <= 0:\n",
        "            if self.task == 'classification':\n",
        "                values, counts = np.unique(y, return_counts=True)\n",
        "                return {'leaf': True, 'value': values[np.argmax(counts)]}\n",
        "            else:\n",
        "                return {'leaf': True, 'value': np.mean(y)}\n",
        "\n",
        "        left_mask = X[:, feature] <= threshold\n",
        "        right_mask = ~left_mask\n",
        "\n",
        "        left_subtree = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
        "        right_subtree = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
        "\n",
        "        return {\n",
        "            'leaf': False,\n",
        "            'feature': feature,\n",
        "            'threshold': threshold,\n",
        "            'left': left_subtree,\n",
        "            'right': right_subtree\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(np.array(X), np.array(y))\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        if node['leaf']:\n",
        "            return node['value']\n",
        "\n",
        "        if x[node['feature']] <= node['threshold']:\n",
        "            return self._predict_one(x, node['left'])\n",
        "        else:\n",
        "            return self._predict_one(x, node['right'])\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x, self.tree) for x in np.array(X)])\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if self.task != 'classification':\n",
        "            raise ValueError(\"predict_proba доступен только для классификации\")\n",
        "        predictions = self.predict(X)\n",
        "        probs = np.zeros((len(predictions), 2))\n",
        "        probs[:, 1] = predictions\n",
        "        probs[:, 0] = 1 - predictions\n",
        "        return probs\n",
        "\n",
        "simple_tree_clf = SimpleDecisionTree(max_depth=5, task='classification')\n",
        "simple_tree_clf.fit(X_train_stroke_processed, y_train_stroke)\n",
        "y_pred_simple = simple_tree_clf.predict(X_test_stroke_processed)\n",
        "\n",
        "acc_simple = accuracy_score(y_test_stroke, y_pred_simple)\n",
        "f1_simple = f1_score(y_test_stroke, y_pred_simple)\n",
        "\n",
        "print(\"\\nКлассификация (Stroke Prediction):\")\n",
        "print(f\"Accuracy: {acc_simple:.4f}\")\n",
        "print(f\"F1-Score: {f1_simple:.4f}\")\n",
        "print()\n",
        "\n",
        "simple_tree_reg = SimpleDecisionTree(max_depth=5, task='regression')\n",
        "simple_tree_reg.fit(X_train_exam_processed, y_train_exam)\n",
        "y_pred_simple_reg = simple_tree_reg.predict(X_test_exam_processed)\n",
        "\n",
        "mae_simple = mean_absolute_error(y_test_exam, y_pred_simple_reg)\n",
        "r2_simple = r2_score(y_test_exam, y_pred_simple_reg)\n",
        "\n",
        "print(\"\\nРегрессия (Exam Performance):\")\n",
        "print(f\"MAE: {mae_simple:.4f}\")\n",
        "print(f\"R²:  {r2_simple:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enNFdkqejlYd",
        "outputId": "e6fc1032-88ad-407c-efb3-3cd58f03c210"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Классификация (Stroke Prediction):\n",
            "Accuracy: 0.9511\n",
            "F1-Score: 0.0000\n",
            "\n",
            "\n",
            "Регрессия (Exam Performance):\n",
            "MAE: 7.4715\n",
            "R²:  0.6971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полученные результаты показывают, что упрощенная реализация решающего дерева демонстрирует сходную с sklearn производительность в задаче регрессии (R² 0.6971 против 0.6905 у sklearn, MAE 7.4715 против 7.5625), что свидетельствует о корректности базовой логики алгоритма, однако в задаче классификации наблюдаются критические проблемы - нулевой F1-Score при высокой Accuracy (0.9511) указывает на то, что модель полностью игнорирует минорный класс (инсульты), предсказывая только мажоритарный класс, в отличие от sklearn-реализации, которая после балансировки данных достигала F1-Score 0.1290, что говорит о необходимости доработки механизма работы с несбалансированными данными в кастомной реализации."
      ],
      "metadata": {
        "id": "SfpEZbW8IbVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp_my_knn_clf = SimpleDecisionTree(max_depth=5, task='classification')\n",
        "imp_my_knn_clf.fit(X_train_selected, y_train_balanced)\n",
        "y_pred_my_imp_clf = imp_my_knn_clf.predict(X_test_selected)\n",
        "\n",
        "imp_my_knn_reg = SimpleDecisionTree(max_depth=15, task='regression')\n",
        "imp_my_knn_reg.fit(X_train_exam_selected, y_train_exam)\n",
        "y_pred_my_imp_reg = imp_my_knn_reg.predict(X_test_exam_selected)\n",
        "\n",
        "\n",
        "imp_acc_my_clf = accuracy_score(y_test_stroke, y_pred_my_imp_clf)\n",
        "imp_f1_my_clf = f1_score(y_test_stroke, y_pred_my_imp_clf)\n",
        "\n",
        "print(\"\\nКлассификация (Stroke Prediction):\")\n",
        "print(f\"Accuracy: {imp_acc_my_clf:.4f}\")\n",
        "print(f\"F1-Score: {imp_f1_my_clf:.4f}\")\n",
        "\n",
        "imp_mae_my_reg = mean_absolute_error(y_test_exam, y_pred_my_imp_reg)\n",
        "imp_rmse_my_reg = np.sqrt(mean_squared_error(y_test_exam, y_pred_my_imp_reg))\n",
        "imp_r2_my_reg = r2_score(y_test_exam, y_pred_my_imp_reg)\n",
        "\n",
        "print(\"\\nРегрессия (Exam Performance):\")\n",
        "print(f\"MAE:  {imp_mae_my_reg:.4f}\")\n",
        "print(f\"RMSE: {imp_rmse_my_reg:.4f}\")\n",
        "print(f\"R²:   {imp_r2_my_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubUORnL4JH4q",
        "outputId": "7fb1768b-6cc1-48a2-81d0-80f0c9f4e5ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Классификация (Stroke Prediction):\n",
            "Accuracy: 0.7407\n",
            "F1-Score: 0.2319\n",
            "\n",
            "Регрессия (Exam Performance):\n",
            "MAE:  8.8307\n",
            "RMSE: 11.1043\n",
            "R²:   0.5805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Улчшения показали отличный эффект на задаче классификации, сильно уменьшив значение дисбаланса классов. Тем не менее, результаты регрессии только ухудшились, что может говорить о чрезмерном сокращении признаков"
      ],
      "metadata": {
        "id": "eOdfObdTLB9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Вывод\n",
        "В ходе работы с решающими деревьями было продемонстрировано, что они являются эффективным инструментом как для классификации, так и для регрессии, однако требуют тщательной настройки гиперпараметров (глубины дерева, критериев разделения, минимального количества образцов в узлах) и обработки несбалансированных данных для достижения оптимальных результатов. Кастомная реализация показала работоспособность базового алгоритма, но уступила оптимизированной sklearn-версии в точности, особенно в задаче классификации, где критически важными оказались техники балансировки данных."
      ],
      "metadata": {
        "id": "HrWmwWHdLXE4"
      }
    }
  ]
}