{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Выбор данных\n",
        "\n",
        "#Датасеты\n",
        "- **Датасет:** [Stroke Prediction Dataset](https://www.kaggle.com/datasets/jawairia123/stroke-prediction-dataset)\n",
        "\n",
        " **Задача:** Прогнозирование вероятности инсульта у пациента на основе медицинских и демографических данных.\n",
        "\n",
        "- **Датасет:** [Python Learning & Exam Performance Dataset](https://www.kaggle.com/datasets/emonsharkar/python-learning-and-exam-performance-dataset)\n",
        "\n",
        " **Задача:** Прогнозирование результата экзамена по Python на основе данных об обучении и активности студента.\n",
        "\n",
        "#Метрики\n",
        "- **Для классификации:**\n",
        "  - **F1-score:** так как датасет может быть несбалансированным\n",
        "  - **ROC-AUC:** позволяет оценить качество модели на разных порогах классификации\n",
        "  - **Accuracy**\n",
        "- **Для регрессии:**\n",
        "  - **MAE**\n",
        "  - **RMSE:** более чувствительна к большим ошибкам\n",
        "  - **R²**\n"
      ],
      "metadata": {
        "id": "B6rxjDF7NVtA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Создание бейзлайна и оценка качества\n"
      ],
      "metadata": {
        "id": "9ECoU5qQO-Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, f_regression"
      ],
      "metadata": {
        "id": "p14GJo99XFpi"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично ЛР1"
      ],
      "metadata": {
        "id": "Abmglj5aViCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stroke = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')\n",
        "df_stroke = df_stroke.drop(columns=['id'])\n",
        "df_exam = pd.read_csv('/content/python_learning_exam_performance.csv')\n",
        "df_exam = df_exam.drop(columns=['student_id'])\n",
        "\n",
        "df_stroke['bmi'] = df_stroke['bmi'].fillna(df_stroke['bmi'].median())\n",
        "\n",
        "X_stroke = df_stroke.drop(columns=['stroke'])\n",
        "y_stroke = df_stroke['stroke']\n",
        "X_train_stroke, X_test_stroke, y_train_stroke, y_test_stroke = train_test_split(\n",
        "    X_stroke, y_stroke, test_size=0.2, random_state=42, stratify=y_stroke\n",
        ")\n",
        "\n",
        "cat_cols_stroke = X_train_stroke.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols_stroke = X_train_stroke.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "preprocessor_stroke = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_cols_stroke),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols_stroke)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_stroke_processed = preprocessor_stroke.fit_transform(X_train_stroke)\n",
        "X_test_stroke_processed = preprocessor_stroke.transform(X_test_stroke)\n",
        "df_exam['prior_programming_experience'] = df_exam['prior_programming_experience'].fillna('No')\n",
        "\n",
        "X_exam = df_exam.drop(columns=['final_exam_score'])\n",
        "y_exam = df_exam['final_exam_score']\n",
        "X_train_exam, X_test_exam, y_train_exam, y_test_exam = train_test_split(\n",
        "    X_exam, y_exam, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "cat_cols_exam = X_train_exam.select_dtypes(include=['object']).columns.tolist()\n",
        "num_cols_exam = X_train_exam.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "preprocessor_exam = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), num_cols_exam),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), cat_cols_exam)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X_train_exam_processed = preprocessor_exam.fit_transform(X_train_exam)\n",
        "X_test_exam_processed = preprocessor_exam.transform(X_test_exam)"
      ],
      "metadata": {
        "id": "SRhPv9KEdSKc"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "77Y2LXHqmtmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "log_reg.fit(X_train_stroke_processed, y_train_stroke)\n",
        "y_pred_stroke_log = log_reg.predict(X_test_stroke_processed)\n",
        "y_pred_proba_stroke_log = log_reg.predict_proba(X_test_stroke_processed)[:, 1]\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_exam_processed, y_train_exam)\n",
        "y_pred_exam_lin = lin_reg.predict(X_test_exam_processed)\n",
        "\n",
        "# Оценка качества моделей\n",
        "\n",
        "acc_log = accuracy_score(y_test_stroke, y_pred_stroke_log)\n",
        "f1_log = f1_score(y_test_stroke, y_pred_stroke_log)\n",
        "roc_auc_log = roc_auc_score(y_test_stroke, y_pred_proba_stroke_log)\n",
        "\n",
        "print(\"=== Классификация ===\")\n",
        "print(f\"Accuracy: {acc_log:.4f}\")\n",
        "print(f\"F1-Score: {f1_log:.4f}\")\n",
        "print(f\"ROC-AUC:  {roc_auc_log:.4f}\")\n",
        "print()\n",
        "\n",
        "mae_lin = mean_absolute_error(y_test_exam, y_pred_exam_lin)\n",
        "rmse_lin = np.sqrt(mean_squared_error(y_test_exam, y_pred_exam_lin))\n",
        "r2_lin = r2_score(y_test_exam, y_pred_exam_lin)\n",
        "\n",
        "print(\"=== Регрессия ===\")\n",
        "print(f\"MAE:  {mae_lin:.4f}\")\n",
        "print(f\"RMSE: {rmse_lin:.4f}\")\n",
        "print(f\"R²:   {r2_lin:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9---xR65iNc6",
        "outputId": "c6bca9e1-513c-45fb-f7ba-0e14611b0192"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Классификация ===\n",
            "Accuracy: 0.9521\n",
            "F1-Score: 0.0392\n",
            "ROC-AUC:  0.8417\n",
            "\n",
            "=== Регрессия ===\n",
            "MAE:  5.8876\n",
            "RMSE: 7.2979\n",
            "R²:   0.8188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Анализ результатов**\n",
        "\n",
        "**Логистическая регрессия** показала Accuracy 95.2% и высокий ROC-AUC 0.842, что свидетельствует о хорошей разделительной способности модели, однако крайне низкий F1-Score 0.039 подтверждает серьёзную проблему с дисбалансом классов — модель правильно предсказывает отсутствие инсульта, но плохо выявляет положительные случаи, что критично для медицинской задачи.\n",
        "\n",
        "**Линейная регрессия** продемонстрировала отличные результаты с R²=0.819, объясняя 82% дисперсии данных, при этом MAE=5.89 и RMSE=7.30 указывают на среднюю ошибку менее 6 баллов, что делает модель эффективной для прогнозирования результатов экзамена, хотя и остаётся пространство для улучшения за счёт нелинейных зависимостей и дополнительной обработки признаков.\n"
      ],
      "metadata": {
        "id": "25foCoqkoVhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "ljbpDl5To_Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аналогично ЛР 1 пробуем следующие гипотезы для улучшения результатов\n",
        "\n",
        "-   Балансировка классов\n",
        "-   Подбор гиперпараметров\n",
        "\n",
        "- Отбор признаков\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qGalntx2tllk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_stroke_processed, y_train_stroke)\n",
        "print(f\"   До балансировки: {np.bincount(y_train_stroke)}\")\n",
        "print(f\"   После балансировки: {np.bincount(y_train_balanced)}\")\n",
        "\n",
        "\n",
        "selector_clf = SelectKBest(f_classif, k=8)\n",
        "X_train_selected = selector_clf.fit_transform(X_train_balanced, y_train_balanced)\n",
        "X_test_selected = selector_clf.transform(X_test_stroke_processed)\n",
        "print(f\"   Выбрано {X_train_selected.shape[1]} лучших признаков из {X_train_balanced.shape[1]}\")\n",
        "\n",
        "\n",
        "param_grid_logreg = {\n",
        "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear', 'saga'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "grid_search_logreg = GridSearchCV(\n",
        "    LogisticRegression(random_state=42, class_weight='balanced'),\n",
        "    param_grid_logreg,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "grid_search_logreg.fit(X_train_selected, y_train_balanced)\n",
        "\n",
        "print(f\"   Лучшие параметры: {grid_search_logreg.best_params_}\")\n",
        "\n",
        "best_logreg = grid_search_logreg.best_estimator_\n",
        "y_pred_logreg_improved = best_logreg.predict(X_test_selected)\n",
        "y_pred_proba_logreg_improved = best_logreg.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "acc_logreg_improved = accuracy_score(y_test_stroke, y_pred_logreg_improved)\n",
        "f1_logreg_improved = f1_score(y_test_stroke, y_pred_logreg_improved)\n",
        "roc_auc_logreg_improved = roc_auc_score(y_test_stroke, y_pred_proba_logreg_improved)\n",
        "\n",
        "print(f\"   Accuracy:  {acc_logreg_improved:.4f}\")\n",
        "print(f\"   F1-Score:  {f1_logreg_improved:.4f}\")\n",
        "print(f\"   ROC-AUC:   {roc_auc_logreg_improved:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gegz6_Hto-rK",
        "outputId": "8430a7eb-2002-4801-9926-2678ae1e5728"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   До балансировки: [3889  199]\n",
            "   После балансировки: [3889 3889]\n",
            "   Выбрано 8 лучших признаков из 16\n",
            "   Лучшие параметры: {'C': 0.01, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "   Accuracy:  0.7290\n",
            "   F1-Score:  0.2284\n",
            "   ROC-AUC:   0.8408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "selector_reg = SelectKBest(f_regression, k=10)\n",
        "X_train_exam_selected = selector_reg.fit_transform(X_train_exam_processed, y_train_exam)\n",
        "X_test_exam_selected = selector_reg.transform(X_test_exam_processed)\n",
        "print(f\"   Выбрано {X_train_exam_selected.shape[1]} лучших признаков из {X_train_exam_processed.shape[1]}\")\n",
        "\n",
        "\n",
        "param_grid_reg = {\n",
        "    'fit_intercept': [True, False],\n",
        "    'positive': [True, False],\n",
        "    'copy_X': [True, False]\n",
        "}\n",
        "\n",
        "grid_search_reg = GridSearchCV(\n",
        "    LinearRegression(),\n",
        "    param_grid_reg,\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "grid_search_reg.fit(X_train_exam_selected, y_train_exam)\n",
        "\n",
        "print(f\"   Лучшие параметры: {grid_search_reg.best_params_}\")\n",
        "\n",
        "\n",
        "best_lin_reg = grid_search_reg.best_estimator_\n",
        "y_pred_exam_improved = best_lin_reg.predict(X_test_exam_selected)\n",
        "\n",
        "\n",
        "mae_improved = mean_absolute_error(y_test_exam, y_pred_exam_improved)\n",
        "rmse_improved = np.sqrt(mean_squared_error(y_test_exam, y_pred_exam_improved))\n",
        "r2_improved = r2_score(y_test_exam, y_pred_exam_improved)\n",
        "\n",
        "print(f\"   MAE:   {mae_improved:.4f}\")\n",
        "print(f\"   RMSE:  {rmse_improved:.4f}\")\n",
        "print(f\"   R²:    {r2_improved:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVRxSaav1WDU",
        "outputId": "ad53f80d-a97a-4a59-fd58-382da534df28"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Выбрано 10 лучших признаков из 23\n",
            "   Лучшие параметры: {'copy_X': True, 'fit_intercept': True, 'positive': False}\n",
            "   MAE:   6.4801\n",
            "   RMSE:  8.0722\n",
            "   R²:    0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Сравнение с базовыми результатами**\n",
        "\n",
        "Логистическая регрессия после балансировки классов и отбора признаков показала значительное улучшение: F1-Score вырос с 0.0392 до 0.2284 (почти в 6 раз), что указывает на эффективность борьбы с дисбалансом, хотя Accuracy снизился с 0.9521 до 0.7290 — ожидаемая плата за повышение чувствительности к миноритарному классу. ROC-AUC остался высоким (0.8408), подтверждая хорошую разделительную способность модели.\n",
        "\n",
        "Линейная регрессия с отобранными признаками ухудшила все метрики. Отбор только 10 из 23 признаков привёл к потере важной информации для линейной регрессии. Вероятно, удалённые признаки содержали значимые для предсказания зависимости, или линейная модель требует полного набора признаков для построения оптимальных весов. Для линейной регрессии в этом случае отбор признаков оказался контрпродуктивным — лучше использовать все доступные признаки."
      ],
      "metadata": {
        "id": "__UCedKhFS-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Имплементация собвственной модели\n"
      ],
      "metadata": {
        "id": "SWqGaH0st-t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogisticRegression:\n",
        "    def __init__(self, learning_rate=0.01, n_iter=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_iter = n_iter\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_pred = self._sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            self.weights -= self.learning_rate * dw\n",
        "            self.bias -= self.learning_rate * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self._sigmoid(linear_model)\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return (self.predict_proba(X) >= threshold).astype(int)\n",
        "\n",
        "class MyLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_b = np.c_[np.ones(X.shape[0]), X]\n",
        "        theta = np.linalg.pinv(X_b.T @ X_b) @ X_b.T @ y\n",
        "        self.bias = theta[0]\n",
        "        self.weights = theta[1:]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "my_log_reg = MyLogisticRegression(learning_rate=0.1, n_iter=2000)\n",
        "my_log_reg.fit(X_train_stroke_processed, y_train_stroke)\n",
        "y_pred_my_log = my_log_reg.predict(X_test_stroke_processed)\n",
        "y_pred_proba_my_log = my_log_reg.predict_proba(X_test_stroke_processed)\n",
        "\n",
        "my_lin_reg = MyLinearRegression()\n",
        "my_lin_reg.fit(X_train_exam_selected, y_train_exam)\n",
        "y_pred_my_lin = my_lin_reg.predict(X_test_exam_selected)\n",
        "\n",
        "acc_my_log = accuracy_score(y_test_stroke, y_pred_my_log)\n",
        "f1_my_log = f1_score(y_test_stroke, y_pred_my_log)\n",
        "roc_auc_my_log = roc_auc_score(y_test_stroke, y_pred_proba_my_log)\n",
        "\n",
        "print(\"Логистическая регрессия:\")\n",
        "print(f\"Accuracy: {acc_my_log:.4f}\")\n",
        "print(f\"F1-Score: {f1_my_log:.4f}\")\n",
        "print(f\"ROC-AUC:  {roc_auc_my_log:.4f}\")\n",
        "\n",
        "mae_my_lin = mean_absolute_error(y_test_exam, y_pred_my_lin)\n",
        "rmse_my_lin = np.sqrt(mean_squared_error(y_test_exam, y_pred_my_lin))\n",
        "r2_my_lin = r2_score(y_test_exam, y_pred_my_lin)\n",
        "\n",
        "print(\"\\nЛинейная регрессия:\")\n",
        "print(f\"MAE:  {mae_my_lin:.4f}\")\n",
        "print(f\"RMSE: {rmse_my_lin:.4f}\")\n",
        "print(f\"R²:   {r2_my_lin:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncSwjUosuF92",
        "outputId": "b5a06649-cad7-4187-c5da-5ede89727f4d"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Логистическая регрессия:\n",
            "Accuracy: 0.9511\n",
            "F1-Score: 0.0385\n",
            "ROC-AUC:  0.8313\n",
            "\n",
            "Линейная регрессия:\n",
            "MAE:  6.4801\n",
            "RMSE: 8.0722\n",
            "R²:   0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Имплементация корректна - результаты близки к sklearn. Введём улучшения"
      ],
      "metadata": {
        "id": "SfpEZbW8IbVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp_my_knn_clf = MyLogisticRegression()\n",
        "imp_my_knn_clf.fit(X_train_selected, y_train_balanced)\n",
        "y_pred_my_imp_clf = imp_my_knn_clf.predict(X_test_selected)\n",
        "\n",
        "imp_my_knn_reg = MyLinearRegression()\n",
        "imp_my_knn_reg.fit(X_train_exam_selected, y_train_exam)\n",
        "y_pred_my_imp_reg = imp_my_knn_reg.predict(X_test_exam_selected)\n",
        "\n",
        "\n",
        "imp_acc_my_clf = accuracy_score(y_test_stroke, y_pred_my_imp_clf)\n",
        "imp_f1_my_clf = f1_score(y_test_stroke, y_pred_my_imp_clf)\n",
        "\n",
        "print(\"\\nКлассификация (Stroke Prediction):\")\n",
        "print(f\"Accuracy: {imp_acc_my_clf:.4f}\")\n",
        "print(f\"F1-Score: {imp_f1_my_clf:.4f}\")\n",
        "\n",
        "imp_mae_my_reg = mean_absolute_error(y_test_exam, y_pred_my_imp_reg)\n",
        "imp_rmse_my_reg = np.sqrt(mean_squared_error(y_test_exam, y_pred_my_imp_reg))\n",
        "imp_r2_my_reg = r2_score(y_test_exam, y_pred_my_imp_reg)\n",
        "\n",
        "print(\"\\nРегрессия (Exam Performance):\")\n",
        "print(f\"MAE:  {imp_mae_my_reg:.4f}\")\n",
        "print(f\"RMSE: {imp_rmse_my_reg:.4f}\")\n",
        "print(f\"R²:   {imp_r2_my_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubUORnL4JH4q",
        "outputId": "44ed9ac3-76de-4424-f855-fef7be68cca8"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Классификация (Stroke Prediction):\n",
            "Accuracy: 0.7133\n",
            "F1-Score: 0.2187\n",
            "\n",
            "Регрессия (Exam Performance):\n",
            "MAE:  6.4801\n",
            "RMSE: 8.0722\n",
            "R²:   0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты с улучшением также корректны"
      ],
      "metadata": {
        "id": "eOdfObdTLB9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Вывод\n",
        "Логистическая регрессия показала высокий ROC-AUC (0.841), что свидетельствует о хорошей разделительной способности модели, но низкий F1-Score (0.039) выявил критическую проблему с дисбалансом классов, которая была частично решена применением SMOTE и отбором признаков, повысившим F1 до 0.228; линейная регрессия продемонстрировала отличное качество с R²=0.819, однако отбор признаков незначительно ухудшил метрики (R²=0.778), что указывает на важность сохранения полного набора признаков для линейных моделей, в то время как имплементированные версии обоих алгоритмов подтвердили корректность математических основ, показав результаты, близкие к библиотечным реализациям."
      ],
      "metadata": {
        "id": "HrWmwWHdLXE4"
      }
    }
  ]
}